{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed1f3d5a-11b0-4037-9d8b-ec5fde219d57",
   "metadata": {},
   "source": [
    "# Articles classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c41a24-4d27-41bf-804a-0ad77c00c502",
   "metadata": {},
   "source": [
    "## Libraries and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45669f8b-ccf0-4850-a5be-b3a9b6b7eeb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b49de91-9aa6-45d7-a775-1eca2923c19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoModel, \n",
    "    BertTokenizer, \n",
    "    BertForSequenceClassification,\n",
    "    AdamW,\n",
    "    LongformerTokenizerFast,\n",
    "    LongformerModel, \n",
    "    LongformerConfig\n",
    ")\n",
    "from sklearn.metrics import  (\n",
    "    f1_score, \n",
    "    accuracy_score, \n",
    "    multilabel_confusion_matrix, \n",
    "    confusion_matrix\n",
    ")\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bafc133-e6be-4cae-b530-856e10d998ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "VER = 'vxl1'\n",
    "DATA_PATH = '/home/jovyan/__LABELING/data'\n",
    "MDLS_PATH = f'/home/jovyan/__LABELING/models_{VER}'\n",
    "CONFIG = {\n",
    "    'data_file': 'project-6-at-2024-04-01-08-12-9704f322.json',\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    'bbone': 'kazzand/ru-longformer-tiny-16384', # `kazzand/ru-longformer-base-4096` `kazzand/ru-longformer-tiny-16384`\n",
    "    'dropout': .3,\n",
    "    'targets_type': 'general', # targets can be 'all', explicit', 'general' \n",
    "    'targets': [\n",
    "        'target_0_explicit', \n",
    "        'target_3_explicit', \n",
    "        'target_3_general', \n",
    "        'target_4_explicit',\n",
    "        'target_4_general',\n",
    "        'target_7_explicit',\n",
    "        'target_7_general', \n",
    "        'target_11_explicit', \n",
    "        'target_11_general',\n",
    "        'target_12_explicit', \n",
    "        'target_12_general'\n",
    "    ], \n",
    "    'targets_description': {\n",
    "        'target_0': 'ЦУР отсутствуют', \n",
    "        'target_3': 'ЦУР 3 - Хорошее здоровье и благополучие',\n",
    "        'target_4': 'ЦУР 4 - Качественное образование',\n",
    "        'target_7': 'ЦУР 7 - Недорогостоящая и чистая энергия', \n",
    "        'target_11': 'ЦУР 11 - Устойчивые города',\n",
    "        'target_12': 'ЦУР 12 - Ответственное потребление и производство', \n",
    "    },\n",
    "    'pos_weight': False,\n",
    "    'folds': 5,\n",
    "    'max_seq_len': 10240, # 4096 10240\n",
    "    'batch_size': 6,\n",
    "    'num_workers': 4,\n",
    "    'acc': False,\n",
    "    'epochs': 50,\n",
    "    'lr': 2e-5, # default `2e-5`\n",
    "    'patience': 5,\n",
    "    'seed': 23\n",
    "}\n",
    "if not os.path.exists(MDLS_PATH):\n",
    "    os.mkdir(MDLS_PATH)\n",
    "with open(f'{MDLS_PATH}/config.json', 'w') as file:\n",
    "    json.dump(CONFIG, file)\n",
    "\n",
    "def seed_all(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        torch.backends.cudnn.deterministic = False\n",
    "\n",
    "seed_all(CONFIG['seed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef169c2-be28-4302-9d8b-c9855cd049cd",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0dce51-cc92-4799-b81a-07f6b4a70539",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{DATA_PATH}/{CONFIG[\"data_file\"]}') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "print('total records:', len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6f6eb7-380f-4bb1-84d8-40428db063c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def last_ann(anns):\n",
    "    return sorted(anns, key=lambda d: d['updated_at'])[-1]\n",
    "\n",
    "ds = []\n",
    "for d in data:\n",
    "    dd = {}\n",
    "    dd['idart'] = d['id']\n",
    "    dd['article'] = ' '.join([\n",
    "        d['data']['title'].replace('\\n', ' '),\n",
    "        d['data']['anno'].replace('\\n', ' '),\n",
    "        d['data']['text'].replace('\\n', ' ')\n",
    "    ])\n",
    "    dd.update(\n",
    "        {\n",
    "            x['from_name'] + '_' + x['value']['choices'][0] : 1\n",
    "            for x in last_ann(d['annotations'])['result']\n",
    "        }\n",
    "    )\n",
    "    ds.append(dd)\n",
    "    \n",
    "df = pd.DataFrame(ds)\n",
    "df.fillna(0, inplace=True)\n",
    "seq_len = [len(str(i).split()) for i in df['article']]\n",
    "print('max sequence lenght:', max(seq_len))\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8343465-63a4-40ed-8348-3793e96e7f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "plt.figure(figsize=(8, 4))\n",
    "df['length'] = df['article'].apply(lambda x: len(x.split()))\n",
    "sns.histplot(df[df['length'] < 20000]['length'], bins=30)\n",
    "plt.title('frequence of documents of a given length', fontsize=10)\n",
    "plt.xlabel('length', fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7872312-79cf-4e52-b03d-a7064ff4aacd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def chk_balance(df, target_cols):\n",
    "    print('total:', len(df))\n",
    "    for col in target_cols:\n",
    "        if 'target' in col: print(\n",
    "            col, '\\t',\n",
    "            df[col].sum(), '\\t',\n",
    "            '{:.1%}'.format(df[col].sum() / len(df))\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8506075-0adb-4356-900e-9bb33eec2059",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = sorted(list(set([\n",
    "    c.replace('_explicit', '').replace('_general', '') \n",
    "    for c in CONFIG['targets']\n",
    "])))\n",
    "if CONFIG['targets_type'] == 'explicit':\n",
    "    for col in target_cols:\n",
    "        df[col] = df[col + '_explicit']\n",
    "elif CONFIG['targets_type'] == 'general':\n",
    "    for col in target_cols:\n",
    "        name1 = col + '_explicit'\n",
    "        name2 = col + '_general'\n",
    "        if col == 'target_0':\n",
    "            df[col] = df[name1]\n",
    "        else:\n",
    "            df[col] = df.apply(lambda x: max(x[name1], x[name2]), axis=1)\n",
    "elif CONFIG['targets_type'] == 'all':\n",
    "    target_cols = [col for col in df.columns if 'target' in col]\n",
    "else:\n",
    "    ValueError('`targets_type` parameter error')\n",
    "if CONFIG['targets_type'] != 'all':\n",
    "    df.loc[\n",
    "        df[[c for c in target_cols if 'target_0' not in c]].sum(axis=1) == 0, \n",
    "        'target_0'\n",
    "    ] = 1\n",
    "chk_balance(df, target_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174467ca-410e-4b40-9ccb-25f9ca0d92b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG['target_cols'] = target_cols\n",
    "with open(f'{MDLS_PATH}/config.json', 'w') as file:\n",
    "    json.dump(CONFIG, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a1f6f4-809e-46be-9a84-92c2d1211888",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(CONFIG['folds'], shuffle=True, random_state=CONFIG['seed'])\n",
    "df['fold'] = -1\n",
    "for i, (train_idxs, val_idxs) in enumerate(skf.split(df, df['target_0_explicit'])):\n",
    "    df.loc[val_idxs, 'fold'] = i\n",
    "for fold_num in range(CONFIG['folds']): \n",
    "    train_idxs = np.where((df['fold'] != fold_num))[0]\n",
    "    val_idxs = np.where((df['fold'] == fold_num))[0]\n",
    "    df_train = df.loc[train_idxs]\n",
    "    df_val = df.loc[val_idxs]\n",
    "    print('FOLD', fold_num)\n",
    "    chk_balance(df_train, target_cols)\n",
    "    chk_balance(df_val, target_cols)\n",
    "    print('-' * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0056562-899f-439a-9b9d-8d04f9d9e155",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f903eab-6dea-4048-b1d0-cb80e0d6bfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LongformerArticlesLabeling(torch.nn.Module):\n",
    "    def __init__(self, model_name, target_cols, dropout=None):\n",
    "        super(LongformerArticlesLabeling, self).__init__()\n",
    "        self.longformer = AutoModel.from_pretrained(model_name)\n",
    "        if dropout:\n",
    "            self.dropout = dropout\n",
    "            self.l2 = torch.nn.Dropout(dropout)\n",
    "        if 'tiny' in model_name:\n",
    "            self.fc = torch.nn.Linear(312, len(target_cols))\n",
    "        else:\n",
    "            self.fc = torch.nn.Linear(768, len(target_cols))\n",
    "        \n",
    "    def forward(self, input_ids=None, attention_mask=None, \n",
    "                global_attention_mask=None, \n",
    "                token_type_ids=None, position_ids=None, \n",
    "                inputs_embeds=None):\n",
    "        if global_attention_mask is None:\n",
    "            global_attention_mask = torch.zeros_like(input_ids)\n",
    "            global_attention_mask[:, 0] = 1\n",
    "        _, features = self.longformer(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask = attention_mask,\n",
    "            global_attention_mask = global_attention_mask,\n",
    "            token_type_ids = token_type_ids,\n",
    "            position_ids = position_ids,\n",
    "            return_dict=False\n",
    "        )\n",
    "        if self.dropout: \n",
    "            x = self.l2(features)\n",
    "            output = self.fc(x)\n",
    "        output = self.fc(features)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06398b8-4fc9-4c21-bc21-ac7ae97a7708",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArticlesDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, col, target_cols, tokenizer, max_len):\n",
    "        self.df = df\n",
    "        self.max_len = max_len\n",
    "        self.text = df[col]\n",
    "        self.tokenizer = tokenizer\n",
    "        self.targets = df[target_cols].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        text = self.text[index]\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        attention_mask = inputs['attention_mask']\n",
    "        global_attention_mask = [\n",
    "            [1 if token_id == self.tokenizer.cls_token_id else 0 for token_id in input_ids]\n",
    "            for input_ids in inputs['input_ids']\n",
    "        ]\n",
    "        return {\n",
    "            'ids': ids[0], \n",
    "            'attention_mask': attention_mask[0],\n",
    "            'global_attention_mask': torch.tensor(global_attention_mask, dtype=torch.long)[0],\n",
    "            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606fc5c2-c164-4f1c-b37b-977603314178",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArticlesTrainer:\n",
    "    def __init__(self, model, device, \n",
    "                 optimizer, scheduler, \n",
    "                 criterion, pos_weight,\n",
    "                 acc_flag=True):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.criterion = criterion\n",
    "        self.pos_weight = pos_weight\n",
    "        self.acc_flag = acc_flag\n",
    "        if acc_flag:\n",
    "            self.best_val_acc = 0\n",
    "        else:\n",
    "            self.best_val_loss = np.inf\n",
    "        self.val_losses = []\n",
    "        self.train_losses = []\n",
    "        self.val_acc = []\n",
    "        self.lastmodel = None\n",
    "        \n",
    "    def fit(self, epochs, train_loader, val_loader, \n",
    "            max_patience, save_mode='best', save_name='model'):     \n",
    "        n_patience = 0\n",
    "        for n_epoch in range(1, epochs + 1):\n",
    "            self.info_message('EPOCH: {}', n_epoch)\n",
    "            train_loss, train_time = self.train_epoch(train_loader)\n",
    "            val_loss, val_acc, val_f1_mic, val_f1_mac, val_time = self.val_epoch(val_loader)\n",
    "            self.train_losses.append(train_loss)\n",
    "            self.val_losses.append(val_loss)\n",
    "            self.val_acc.append(val_acc)\n",
    "            self.info_message(\n",
    "                'epoch train: {} | loss: {:.2f} | time: {:.0f} sec',\n",
    "                n_epoch, train_loss, train_time\n",
    "            )\n",
    "            self.info_message(\n",
    "                'epoch val: {} | loss: {:.2f} | ' +\n",
    "                'acc: {:.2f} | f1 micro: {:.2f} | f1 macro: {:.2f} | ' +\n",
    "                'time: {:.0f} sec',\n",
    "                n_epoch, val_loss, val_acc, val_f1_mic, val_f1_mac, val_time\n",
    "            )\n",
    "            if self.acc_flag:\n",
    "                if self.best_val_acc < val_acc: \n",
    "                    self.save_model(n_epoch, save_mode, save_name, val_loss, val_acc)\n",
    "                    self.info_message(\n",
    "                        'val accuracy improved {:.2f} -> {:.2f} | saved model to \"{}\"', \n",
    "                        self.best_val_acc, val_acc, self.lastmodel\n",
    "                    )\n",
    "                    self.best_val_acc = val_acc\n",
    "                    n_patience = 0\n",
    "                else:\n",
    "                    n_patience += 1\n",
    "            else:\n",
    "                if self.best_val_loss > val_loss: \n",
    "                    self.save_model(n_epoch, save_mode, save_name, val_loss, val_acc)\n",
    "                    self.info_message(\n",
    "                        'val loss improved {:.2f} -> {:.2f} | saved model to \"{}\"', \n",
    "                        self.best_val_loss, val_loss, self.lastmodel\n",
    "                    )\n",
    "                    self.best_val_loss = val_loss\n",
    "                    n_patience = 0\n",
    "                else:\n",
    "                    n_patience += 1\n",
    "            if n_patience >= max_patience:\n",
    "                self.info_message(\n",
    "                    '\\nno improvement for last {} epochs', \n",
    "                    n_patience\n",
    "                )\n",
    "                break\n",
    "        history = {\n",
    "            'train losses': self.train_losses, \n",
    "            'val losses': self.val_losses, \n",
    "            'val accuracy': self.val_acc\n",
    "        }\n",
    "        return history\n",
    "            \n",
    "    def train_epoch(self, train_loader):\n",
    "        self.model.train()\n",
    "        t = time.time()\n",
    "        sum_loss = 0\n",
    "        for step, batch in enumerate(train_loader, 1):\n",
    "            ids = batch['ids'].to(self.device, dtype=torch.long)\n",
    "            mask = batch['attention_mask'].to(self.device, dtype=torch.long)\n",
    "            gamask = batch['global_attention_mask'].to(self.device, dtype=torch.long)\n",
    "            targets = batch['targets'].to(self.device, dtype=torch.float)\n",
    "            if len(self.pos_weight):\n",
    "                pos_weight = torch.from_numpy(self.pos_weight).to(\n",
    "                    self.device, \n",
    "                    dtype=torch.float\n",
    "                )\n",
    "            else:\n",
    "                pos_weight = None\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(\n",
    "                input_ids=ids,\n",
    "                attention_mask=mask,\n",
    "                global_attention_mask=gamask\n",
    "            )\n",
    "            loss = self.criterion(outputs, targets, pos_weight=pos_weight)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            if self.scheduler: \n",
    "                self.scheduler.step()\n",
    "            sum_loss += loss.detach().item()   \n",
    "            self.info_message(\n",
    "                'train step {}/{} | train loss: {:.4f}           ',\n",
    "                step, len(train_loader), sum_loss / step, end='\\r'\n",
    "            )\n",
    "        return sum_loss / len(train_loader), int(time.time() - t)\n",
    "    \n",
    "    def val_epoch(self, val_loader):\n",
    "        self.model.eval()\n",
    "        t = time.time()\n",
    "        sum_loss = 0\n",
    "        y_all = []\n",
    "        outputs_all = []\n",
    "        for step, batch in enumerate(val_loader, 1):\n",
    "            with torch.no_grad():\n",
    "                ids = batch['ids'].to(self.device, dtype=torch.long)\n",
    "                mask = batch['attention_mask'].to(self.device, dtype=torch.long)\n",
    "                targets = batch['targets'].to(self.device, dtype=torch.float)\n",
    "                outputs = self.model(ids, mask)\n",
    "                if len(self.pos_weight):\n",
    "                    pos_weight = torch.from_numpy(self.pos_weight).to(\n",
    "                        self.device, \n",
    "                        dtype=torch.float\n",
    "                    )\n",
    "                else:\n",
    "                    pos_weight = None\n",
    "                loss = self.criterion(outputs, targets, pos_weight=pos_weight)\n",
    "                sum_loss += loss.detach().item()\n",
    "                y_all.extend(targets.cpu().detach().numpy().tolist())\n",
    "                outputs_all.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
    "            self.info_message(\n",
    "                'val step {}/{} | val loss: {:.4f}               ', \n",
    "                step, len(val_loader), sum_loss / step, end='\\r'\n",
    "            )\n",
    "        outputs_all = np.array(outputs_all) > .5\n",
    "        acc = accuracy_score(y_all, outputs_all)\n",
    "        mcm = multilabel_confusion_matrix(outputs_all, y_all)\n",
    "        self.cm_print(mcm, start='\\n')\n",
    "        f1_mic = f1_score(y_all, outputs_all, average='micro')\n",
    "        f1_mac = f1_score(y_all, outputs_all, average='macro')\n",
    "        return sum_loss / len(val_loader), acc, f1_mic, f1_mac, int(time.time() - t)\n",
    "    \n",
    "    def save_model(self, n_epoch, save_mode, save_name, loss, acc):\n",
    "        if save_mode == 'best':\n",
    "            self.lastmodel = f'{MDLS_PATH}/{save_name}.pth'\n",
    "        else:\n",
    "            self.lastmodel = f'{MDLS_PATH}/{save_name}-e{n_epoch}-loss{loss:.3f}-acc{acc:.3f}.pth'\n",
    "        dict_save = {\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'n_epoch': n_epoch,\n",
    "        }\n",
    "        if self.acc_flag:\n",
    "            dict_save['best_val_acc'] = self.best_val_acc\n",
    "        else:\n",
    "            dict_save['best_val_loss'] = self.best_val_loss\n",
    "        torch.save(dict_save, self.lastmodel)\n",
    "    \n",
    "    def display_plots(self):\n",
    "        fig, axes = plt.subplots(figsize=(16, 4), nrows=1, ncols=2)\n",
    "        axes[0].set_title(f'training and validation losses')\n",
    "        axes[0].plot(self.val_losses, label='val')\n",
    "        axes[0].plot(self.train_losses, label='train')\n",
    "        axes[0].set_xlabel('iterations')\n",
    "        axes[0].set_ylabel('loss')\n",
    "        axes[0].legend()\n",
    "        axes[1].set_title(f'validation accuracy')\n",
    "        axes[1].plot(self.val_acc, label='val')\n",
    "        axes[1].set_xlabel('iterations')\n",
    "        axes[1].set_ylabel('accuracy')\n",
    "        axes[1].legend()\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "    \n",
    "    @staticmethod\n",
    "    def info_message(message, *args, end='\\n'):\n",
    "        print(message.format(*args), end=end)\n",
    "        \n",
    "    @staticmethod\n",
    "    def cm_print(mcm, start='\\n'):\n",
    "        print(start)\n",
    "        for cm in mcm:\n",
    "            print(cm)\n",
    "            print('-' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b8e5eb-0cac-4d1d-a34c-e04e5bf66e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_pos_weight(df, target_cols, pos_weight):\n",
    "    num_pos_samples = df[target_cols].sum()\n",
    "    num_neg_samples = len(df) - num_pos_samples\n",
    "    weights = pos_weight * np.array(num_neg_samples / num_pos_samples)\n",
    "    print('weights used:', weights)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da02211a-f5ec-4bf3-8c98-e711f3b75f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_art_model(df_train, df_val, target_cols,\n",
    "                    device, model_name, max_seq_len,\n",
    "                    epochs, save_name, patience, \n",
    "                    batch_size, num_workers):\n",
    "    print('=' * 20, f'MODEL TRAIN - {save_name}', '=' * 20)\n",
    "    print('train:', df_train.shape, '| val:', df_val.shape)\n",
    "    tokenizer = LongformerTokenizerFast.from_pretrained(model_name)\n",
    "    train_dataset = ArticlesDataset(\n",
    "        df=df_train, \n",
    "        col='article',\n",
    "        target_cols=target_cols,\n",
    "        tokenizer=tokenizer, \n",
    "        max_len=max_seq_len\n",
    "    )\n",
    "    val_dataset = ArticlesDataset(\n",
    "        df=df_val, \n",
    "        col='article',\n",
    "        target_cols=target_cols,\n",
    "        tokenizer=tokenizer,\n",
    "        max_len=max_seq_len\n",
    "    )\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers, \n",
    "        shuffle=True,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=batch_size, \n",
    "        num_workers=num_workers, \n",
    "        shuffle=False, \n",
    "        pin_memory=True\n",
    "    )\n",
    "    model = LongformerArticlesLabeling(\n",
    "        model_name=model_name, \n",
    "        target_cols=target_cols,\n",
    "        dropout=CONFIG['dropout']\n",
    "    )\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=CONFIG['lr'], weight_decay=1e-6)\n",
    "    scheduler = None\n",
    "    criterion = nn.functional.binary_cross_entropy_with_logits\n",
    "    if CONFIG['pos_weight']:\n",
    "        pos_weight = df_pos_weight(df_train, target_cols, CONFIG['pos_weight'])\n",
    "    else:\n",
    "        pos_weight = []\n",
    "    trainer = ArticlesTrainer(\n",
    "        model, \n",
    "        device, \n",
    "        optimizer, \n",
    "        scheduler,\n",
    "        criterion,\n",
    "        pos_weight,\n",
    "        acc_flag=CONFIG['acc']\n",
    "    )\n",
    "    history = trainer.fit(\n",
    "        epochs, \n",
    "        train_loader, \n",
    "        val_loader, \n",
    "        save_mode='best', \n",
    "        save_name=save_name,\n",
    "        max_patience=patience\n",
    "    )\n",
    "    trainer.display_plots()\n",
    "    with open(f'{MDLS_PATH}/history_{save_name}.json', 'w') as file:\n",
    "        json.dump(history, file)\n",
    "    return trainer.lastmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d2704c-8d6b-47e4-95db-316ac6f91997",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_files = []\n",
    "for fold_num in range(CONFIG['folds']): \n",
    "    train_idxs = np.where((df['fold'] != fold_num))[0]\n",
    "    val_idxs = np.where((df['fold'] == fold_num))[0]\n",
    "    df_train = df.loc[train_idxs]\n",
    "    df_val = df.loc[val_idxs]\n",
    "    df_train.reset_index(drop=True, inplace=True)\n",
    "    df_val.reset_index(drop=True, inplace=True)\n",
    "    model_files.append(train_art_model(\n",
    "        df_train, \n",
    "        df_val, \n",
    "        target_cols,\n",
    "        device=CONFIG['device'], \n",
    "        model_name=CONFIG['bbone'],\n",
    "        max_seq_len=CONFIG['max_seq_len'],\n",
    "        epochs=CONFIG['epochs'], \n",
    "        save_name=f'model_{fold_num}',\n",
    "        patience=CONFIG['patience'], \n",
    "        batch_size=CONFIG['batch_size'],\n",
    "        num_workers=CONFIG['num_workers']\n",
    "    ))\n",
    "print(model_files)\n",
    "with open(f'{MDLS_PATH}/model_files.json', 'w') as file:\n",
    "    json.dump(model_files, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527f67ab-002f-42ee-a86e-e0c735384705",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a61862-37d4-42b1-b54f-e1b1fae1e6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{MDLS_PATH}/model_files.json', 'r') as file:\n",
    "    model_files = json.load(file)\n",
    "print(\"models files loaded:\", model_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd869b8-e1ba-486e-b9f0-89c7f86bb54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(model_file, df, target_cols, \n",
    "          model_name, max_seq_len,\n",
    "          device, batch_size, num_workers):\n",
    "    print('PREDICT:', model_file, df.shape)\n",
    "    tokenizer = LongformerTokenizerFast.from_pretrained(model_name)\n",
    "    pred_dataset = ArticlesDataset(\n",
    "        df=df, \n",
    "        col='article',\n",
    "        target_cols=target_cols,\n",
    "        tokenizer=tokenizer, \n",
    "        max_len=max_seq_len\n",
    "    )\n",
    "    pred_loader = torch.utils.data.DataLoader(\n",
    "        pred_dataset, \n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers, \n",
    "        shuffle=False,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    model = LongformerArticlesLabeling(\n",
    "        model_name=model_name, \n",
    "        target_cols=target_cols,\n",
    "        dropout=CONFIG['dropout']\n",
    "    )\n",
    "    model.to(device)\n",
    "    checkpoint = torch.load(model_file)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    outputs_all = []\n",
    "    for step, batch in enumerate(pred_loader, 1):\n",
    "        with torch.no_grad():\n",
    "            ids = batch['ids'].to(device, dtype=torch.long)\n",
    "            mask = batch['attention_mask'].to(device, dtype=torch.long)\n",
    "            outputs = model(ids, mask)\n",
    "            outputs_all.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
    "    df_pred = pd.DataFrame(outputs_all) \n",
    "    df_pred.columns = [c + '_pred' for c in target_cols]\n",
    "    return df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc40dc7e-3f6c-4509-8afd-d97d7b0c4bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = pd.DataFrame()\n",
    "for model_file in tqdm(model_files):\n",
    "    df_pred_tmp = infer(\n",
    "        model_file=model_file, \n",
    "        df=df_val, \n",
    "        target_cols=target_cols,\n",
    "        model_name=CONFIG['bbone'],\n",
    "        max_seq_len=CONFIG['max_seq_len'],\n",
    "        device=CONFIG['device'], \n",
    "        batch_size=CONFIG['batch_size'],\n",
    "        num_workers=CONFIG['num_workers']\n",
    "    )\n",
    "    if len(df_pred):\n",
    "        df_pred += df_pred_tmp\n",
    "    else:\n",
    "        df_pred = df_pred_tmp\n",
    "df_pred /= len(model_files)\n",
    "display(df_pred.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a60296-54f9-4e53-ae42-32db1c11419f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_unique = target_cols\n",
    "mcm = multilabel_confusion_matrix(\n",
    "    (df_pred > .5).values, \n",
    "    df_val[target_cols].values\n",
    ")\n",
    "for c, cm in zip(target_cols, mcm):\n",
    "    print(\n",
    "        c, '\\t',\n",
    "        df_val[c].sum(), '\\t',\n",
    "            '{:.1%}'.format(df[c].sum() / len(df)),\n",
    "    )\n",
    "    print(cm)\n",
    "    print('=' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d49622-d912-4542-806d-b468c033208c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df_val.loc[1, 'article']\n",
    "print(text[:500], len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c8436e-a69c-4d9a-a256-6b6c287db9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'article': [text]}\n",
    "d.update(dict(zip(target_cols, [0] * len(target_cols))))\n",
    "df_txt = pd.DataFrame(d)\n",
    "df_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff611cce-36e2-4b20-986a-4dd5a657d998",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_pred = pd.DataFrame()\n",
    "for model_file in tqdm(model_files):\n",
    "    df_pred_tmp = infer(\n",
    "        model_file=model_file, \n",
    "        df=df_txt, \n",
    "        target_cols=target_cols,\n",
    "        model_name=CONFIG['bbone'],\n",
    "        max_seq_len=CONFIG['max_seq_len'],\n",
    "        device=CONFIG['device'], \n",
    "        batch_size=CONFIG['batch_size'],\n",
    "        num_workers=CONFIG['num_workers']\n",
    "    )\n",
    "    if len(df_pred):\n",
    "        df_pred += df_pred_tmp\n",
    "    else:\n",
    "        df_pred = df_pred_tmp\n",
    "df_pred /= len(model_files)\n",
    "df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711262a7-cffb-4089-a77f-413d66d1c547",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0c43deed812d4c089a4986e519df7b0c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "1c81ccb0a85d4638be3853da9e642066": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_8042a7100794444088663dff927c2379",
       "style": "IPY_MODEL_515b6b9ac24244afa336760add3282eb",
       "value": " 5/5 [01:33&lt;00:00, 18.65s/it]"
      }
     },
     "2200ab1746e84a17a27b42574720a19d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3553ddd6d145404bb522efd809b3af7c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_744be5c0c3174c26a6e889031a251c1b",
       "style": "IPY_MODEL_c5474e4b79db4bcc9b892b244a1d601e",
       "value": "100%"
      }
     },
     "515b6b9ac24244afa336760add3282eb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "744be5c0c3174c26a6e889031a251c1b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "75ce5a3e1f5e479a841201bc9cce9b42": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8042a7100794444088663dff927c2379": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8bf0371b1b4748d781499e8778ee9071": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8fdd166482bf43e19652d9bf9b9d8794": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_3553ddd6d145404bb522efd809b3af7c",
        "IPY_MODEL_ce218975365e4e08a5d49939b96ec4e8",
        "IPY_MODEL_c3096dbf319142e7a0ccfb890d12f452"
       ],
       "layout": "IPY_MODEL_f856d75bae224fc9a458c3735a8eb491"
      }
     },
     "9dfd7670ed1b4a6ebbe1775167f084a8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_ee760a91c006460ea342e242f8c492ae",
        "IPY_MODEL_e16034e213da46279e6211e1b5511d86",
        "IPY_MODEL_1c81ccb0a85d4638be3853da9e642066"
       ],
       "layout": "IPY_MODEL_2200ab1746e84a17a27b42574720a19d"
      }
     },
     "c2b45292f18e462397b733b067804a2b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c3096dbf319142e7a0ccfb890d12f452": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_75ce5a3e1f5e479a841201bc9cce9b42",
       "style": "IPY_MODEL_ffad9b389aae43e683aeaa1054851a73",
       "value": " 5/5 [00:17&lt;00:00,  3.45s/it]"
      }
     },
     "c5474e4b79db4bcc9b892b244a1d601e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c940b67dc30c4715b7cd36768b028201": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ce218975365e4e08a5d49939b96ec4e8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_f74160c9a0ad495c9155ad555af71ec2",
       "max": 5,
       "style": "IPY_MODEL_fad675a954d34c50a0cae3d34125ad92",
       "value": 5
      }
     },
     "e16034e213da46279e6211e1b5511d86": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_8bf0371b1b4748d781499e8778ee9071",
       "max": 5,
       "style": "IPY_MODEL_0c43deed812d4c089a4986e519df7b0c",
       "value": 5
      }
     },
     "ee760a91c006460ea342e242f8c492ae": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_c940b67dc30c4715b7cd36768b028201",
       "style": "IPY_MODEL_c2b45292f18e462397b733b067804a2b",
       "value": "100%"
      }
     },
     "f74160c9a0ad495c9155ad555af71ec2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f856d75bae224fc9a458c3735a8eb491": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "fad675a954d34c50a0cae3d34125ad92": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "ffad9b389aae43e683aeaa1054851a73": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
